{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 Lab: Building Your First ML Models\n",
    "\n",
    "**CS 203: Software Tools and Techniques for AI**\n",
    "\n",
    "In this lab, you'll learn to:\n",
    "1. Build baseline models (Logistic Regression, Decision Tree, Random Forest)\n",
    "2. Use cross-validation for reliable evaluation\n",
    "3. Tune hyperparameters with GridSearchCV\n",
    "4. Try AutoML with AutoGluon\n",
    "5. Use transfer learning for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Create Sample Netflix Movie Data\n",
    "\n",
    "Let's create a synthetic dataset similar to what we've been working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic movie data\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "# Generate features\n",
    "genres = np.random.choice(['Action', 'Comedy', 'Drama', 'Horror', 'Sci-Fi'], n_samples)\n",
    "budgets = np.random.uniform(5, 300, n_samples)  # Budget in millions\n",
    "runtimes = np.random.uniform(80, 180, n_samples)  # Runtime in minutes\n",
    "is_sequel = np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "star_power = np.random.uniform(1, 10, n_samples)  # Actor popularity score\n",
    "\n",
    "# Generate target (success) with some logic\n",
    "success_prob = (\n",
    "    0.3 +  # Base probability\n",
    "    0.002 * budgets +  # Higher budget helps\n",
    "    0.02 * star_power +  # Star power helps\n",
    "    0.1 * is_sequel +  # Sequels have slight advantage\n",
    "    np.where(genres == 'Action', 0.1, 0) +  # Action does well\n",
    "    np.random.normal(0, 0.1, n_samples)  # Random noise\n",
    ")\n",
    "success_prob = np.clip(success_prob, 0, 1)\n",
    "success = (np.random.random(n_samples) < success_prob).astype(int)\n",
    "\n",
    "# Create DataFrame\n",
    "movies = pd.DataFrame({\n",
    "    'genre': genres,\n",
    "    'budget': budgets,\n",
    "    'runtime': runtimes,\n",
    "    'is_sequel': is_sequel,\n",
    "    'star_power': star_power,\n",
    "    'success': success\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {movies.shape}\")\n",
    "print(f\"\\nSuccess rate: {movies['success'].mean():.1%}\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variable\n",
    "le = LabelEncoder()\n",
    "movies['genre_encoded'] = le.fit_transform(movies['genre'])\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = ['genre_encoded', 'budget', 'runtime', 'is_sequel', 'star_power']\n",
    "X = movies[feature_cols]\n",
    "y = movies['success']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: The Dumbest Baseline\n",
    "\n",
    "Before building any model, let's see what accuracy we get by just predicting the most common class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority class classifier\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy_acc = dummy.score(X_test, y_test)\n",
    "\n",
    "print(f\"Majority class baseline accuracy: {dummy_acc:.1%}\")\n",
    "print(f\"\\nThis is what we need to beat!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Baseline Models\n",
    "\n",
    "### 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression - the simplest model\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_acc = lr.score(X_test, y_test)\n",
    "print(f\"Logistic Regression accuracy: {lr_acc:.1%}\")\n",
    "print(f\"Improvement over baseline: {(lr_acc - dummy_acc)*100:.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at feature importance (coefficients)\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'coefficient': lr.coef_[0]\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"Feature importance (Logistic Regression):\")\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_acc = dt.score(X_test, y_test)\n",
    "print(f\"Decision Tree accuracy: {dt_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt, feature_names=feature_cols, class_names=['Fail', 'Success'], \n",
    "          filled=True, rounded=True, fontsize=10)\n",
    "plt.title(\"Decision Tree for Movie Success\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest - often the best simple model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_acc = rf.score(X_test, y_test)\n",
    "print(f\"Random Forest accuracy: {rf_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Majority Baseline', 'Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
    "    'Accuracy': [dummy_acc, lr_acc, dt_acc, rf_acc]\n",
    "})\n",
    "\n",
    "results['Improvement'] = results['Accuracy'] - dummy_acc\n",
    "results = results.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "colors = ['gray' if x == 'Majority Baseline' else 'steelblue' for x in results['Model']]\n",
    "plt.barh(results['Model'], results['Accuracy'], color=colors)\n",
    "plt.axvline(x=dummy_acc, color='red', linestyle='--', label='Baseline')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Model Comparison')\n",
    "plt.xlim(0, 1)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Cross-Validation\n",
    "\n",
    "A single train/test split can be misleading. Let's use 5-fold cross-validation for more reliable estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for all models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'Mean Accuracy': scores.mean(),\n",
    "        'Std': scores.std(),\n",
    "        'Scores': scores\n",
    "    })\n",
    "    print(f\"{name}: {scores.mean():.1%} ± {scores.std():.1%}\")\n",
    "    print(f\"  Individual folds: {[f'{s:.1%}' for s in scores]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV results\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = range(len(cv_df))\n",
    "plt.bar(x, cv_df['Mean Accuracy'], yerr=cv_df['Std'], capsize=5, color='steelblue')\n",
    "plt.xticks(x, cv_df['Model'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('5-Fold Cross-Validation Results')\n",
    "plt.ylim(0.5, 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Hyperparameter Tuning\n",
    "\n",
    "### 7.1 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "print(f\"Total combinations to try: {3 * 4 * 3} = 36\")\n",
    "print(\"This might take a moment...\\n\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV accuracy: {grid_search.best_score_:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Random Search (Faster Alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "# Random Search - sample random combinations\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': randint(3, 20),\n",
    "    'min_samples_split': randint(2, 20)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_dist,\n",
    "    n_iter=20,  # Only try 20 random combinations\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X, y)\n",
    "\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Best CV accuracy: {random_search.best_score_:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare tuned vs default\n",
    "default_rf = RandomForestClassifier(random_state=42)\n",
    "default_scores = cross_val_score(default_rf, X, y, cv=5)\n",
    "\n",
    "tuned_rf = grid_search.best_estimator_\n",
    "tuned_scores = cross_val_score(tuned_rf, X, y, cv=5)\n",
    "\n",
    "print(f\"Default RF: {default_scores.mean():.1%} ± {default_scores.std():.1%}\")\n",
    "print(f\"Tuned RF:   {tuned_scores.mean():.1%} ± {tuned_scores.std():.1%}\")\n",
    "print(f\"\\nImprovement: {(tuned_scores.mean() - default_scores.mean())*100:.1f} percentage points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: AutoML with AutoGluon (Optional)\n",
    "\n",
    "If you have AutoGluon installed, try this section. If not, skip to the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install AutoGluon (takes a while)\n",
    "# !pip install autogluon\n",
    "\n",
    "try:\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    AUTOGLUON_AVAILABLE = True\n",
    "    print(\"AutoGluon is available!\")\n",
    "except ImportError:\n",
    "    AUTOGLUON_AVAILABLE = False\n",
    "    print(\"AutoGluon not installed. Skip this section or install with: pip install autogluon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AUTOGLUON_AVAILABLE:\n",
    "    # Prepare data for AutoGluon\n",
    "    train_data = movies[['genre', 'budget', 'runtime', 'is_sequel', 'star_power', 'success']]\n",
    "    \n",
    "    # Train with AutoGluon (time_limit in seconds)\n",
    "    predictor = TabularPredictor(label='success', eval_metric='accuracy')\n",
    "    predictor.fit(train_data, time_limit=120)  # 2 minutes\n",
    "    \n",
    "    # Show leaderboard\n",
    "    print(\"\\nAutoGluon Leaderboard:\")\n",
    "    print(predictor.leaderboard())\n",
    "else:\n",
    "    print(\"Skipping AutoGluon section.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Transfer Learning for Text (Demo)\n",
    "\n",
    "Let's see how transfer learning works with a pretrained model for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers if not available\n",
    "# !pip install transformers\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "    print(\"Transformers is available!\")\n",
    "except ImportError:\n",
    "    TRANSFORMERS_AVAILABLE = False\n",
    "    print(\"Transformers not installed. Skip this section or install with: pip install transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRANSFORMERS_AVAILABLE:\n",
    "    # Load pretrained sentiment classifier\n",
    "    classifier = pipeline(\"sentiment-analysis\")\n",
    "    \n",
    "    # Test on movie reviews\n",
    "    reviews = [\n",
    "        \"This movie was absolutely fantastic! The acting was superb.\",\n",
    "        \"Terrible film. Complete waste of time and money.\",\n",
    "        \"It was okay, nothing special but not bad either.\",\n",
    "        \"A masterpiece! One of the best movies I've ever seen.\",\n",
    "        \"Boring and predictable. Would not recommend.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Transfer Learning Demo: Sentiment Analysis\\n\")\n",
    "    print(\"Using a pretrained model (no training needed!)\\n\")\n",
    "    \n",
    "    for review in reviews:\n",
    "        result = classifier(review)[0]\n",
    "        print(f\"Review: '{review[:50]}...'\")\n",
    "        print(f\"  → {result['label']} (confidence: {result['score']:.1%})\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"Skipping transfer learning section.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMajority Baseline:       {dummy_acc:.1%}\")\n",
    "print(f\"Logistic Regression:     {lr_acc:.1%}\")\n",
    "print(f\"Decision Tree:           {dt_acc:.1%}\")\n",
    "print(f\"Random Forest:           {rf_acc:.1%}\")\n",
    "print(f\"Tuned Random Forest:     {grid_search.best_score_:.1%} (CV)\")\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"1. Always compare against a baseline!\")\n",
    "print(\"2. Use cross-validation for reliable estimates\")\n",
    "print(\"3. Hyperparameter tuning can improve accuracy\")\n",
    "print(\"4. Random Forest is often a great default choice\")\n",
    "print(\"5. AutoML can find good models automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try these on your own:\n",
    "\n",
    "1. **Add more features**: What if you had director name, release month, etc.?\n",
    "2. **Try other models**: SVM, XGBoost, LightGBM\n",
    "3. **Feature engineering**: Create interaction features (budget × star_power)\n",
    "4. **Different metrics**: Try precision, recall, F1 instead of accuracy\n",
    "5. **Larger parameter grid**: More combinations for grid search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
